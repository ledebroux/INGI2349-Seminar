\documentclass[compsoc]{IEEEtran}
\usepackage[utf8]{inputenc}
\author{Olivier Tilmans ~~\and~~ Leonard Debroux}
\title{A Survey of Failure Handling in SDN}
\begin{document}
\maketitle
\begin{abstract}

\end{abstract}

\begin{IEEEkeywords}
Software Defined Network, Protection, Restoration, Failure Detection.
\end{IEEEkeywords}

\section{Introduction}
The issue of treating failures is core in the actual networks as well as in the SDN paradigm. As we want the networks to be efficient and robust, lots of research are done to tackle the problem of failure recovery in better ways than the naive ones.

The basic way of doing so in the SDN's is to constantly probe the network health from the controller to the switches as well as the links, and to react accordingly. Protection can be also done by adding fast restoration entries in the flow tables so that the switches can quickly react to a failure.

In this survey, we'll go through the process of handling failures in a network in a chronological way. Starting with the detection, how to avoid the load on the controller and the massive overhead. Then we'll talk about link and flow protection, how to avoid violating the policies on the network, and how to keep the flow tables from growing exponentially. Finally, we'll talk about recovery and what strategy to adopt on the controller-side to propose efficient recovery and restoration.

\section{Detecting failures}
There are several kind of failures that can affect a network state. Nodes can crash, links can break, resulting in flow which are no longer available. Detecting those failures plays a crucial role for the network to provide good connectivity.

This can be achieved by any agent in the network, depending on the desired performance, the available hardware and level of failures.

\subsection{Controller based detection}
A first approach is to assign the responsibility of the detection to the controller. A naive and inefficient solution would be to have it probe each switch (on each link) in the network using some kind of hello messages (LLDP, \ldots). This solution does not scale well at all, as the controller has to send a linearly increasing number of messages wrt. the link count, the node count and the flow count, this at a sufficient rate to ensure a fast enough detection.

A better approach is proposed by \cite{2013arXiv1308.4465K}. The controller computes an Eulerian cycle across all links under its responsibility, and sends a control message over that cycle using static forwarding rules pre-installed on the switches. As soon as that control message fails to come back, it can perform a binary search using another of static rules in order to locate the link or node that has failed.

The main limitation of this approach is that it cannot handle more than a single link or node failure, as this would break the cycle in multiple places and unlike when a single node was failing, this time the cycle would be broken at multiple places for different reasons, would render the binary search unable to detect both failures (it would only detect one).

\subsection{Switch based detection}
Another approach assigns failure detection to the switches. While these methods are usually much faster, their main drawback is that later on the controller still has to be reached in order to be notified that a failure happened, to let it respond to it, which might induce slower recovery in some cases (e.g. in small networks where LLDP could be used at a very fast rate).

Such system is presented in \cite{6364688}. This paper presents a way to monitor the health of a given tunnel at the egress side, thus in one direction. When receiving OAM messages from the switches along the tunnel, the switch is able to update its state and as soon as it has not received such message in a certain time, it can notify the controller that the path has failed.

Another solution which could be used to monitor the network health at a given time is to simply use BFD on the switches (either by piggybacking it in the data packets, or by generating new packets) and then to notify the controller in case of error.

As these methods are performed at the speed of the data plane, the detection itself is very fast, and the overhead on the network itself and on the controller is quite low (although it might require more complex switches).

\section{Handling the failures}
Once a failure has been detected, the network has to react in order to be able to fulfil its role again, withstanding the failure. There are two kind of reactions which are possible, depending on the time scale at which we want the recovery to happen.
\subsection{By using path protection}
This approach consists of pre-computing backup path for the network flows, and to install them on the switches, which can then use them as soon as a failure is detected, thus avoiding the need for any computation from the controller. Path protection in Openflow networks is achieved by using use of the fast-failover group of flow tables.

The main issue by this techniques lies in the fact that it is not possible to install all possible backup paths for each link (or flow), as the size of the flow tables is limited.

This leads to a solution proposed in \cite{Reitblatt:2013:FDF:2491185.2491187}. It proposes a way for the network programmer to express policies on paths, which must be enforced at all time, even in case of failure (e.g. enforcing that all outgoing traffic must go through the firewall except for the DMZ). This framework then computes all possible backup paths meeting these invariants for the flows needing protection. In the end, this reduces the overall number of backup paths which have to be installed on the switches, as only the flows for which the programmer explicitly provided invariants will be protected.

A complementary approach is presented in \cite{Suchara:2011:NAJ:1993744.1993756}. This paper argues that load balancing and path protection should be treated as one problem. A management system has to compute backup paths for each flows, and those should be used all the time in order to achieve load balancing. Upon a failure, the switches will simply stop using the path that has broke and keep performing load balancing with the remaining ones. It also notifies the management system about it, which can then react to provide a more optimal routing solution in the network. This paper is independent from the routing paradigm used, but using it within SDN's is straightforward.

\subsection{By using restoration techniques}
Restoration techniques, albeit usually slower, provide the most optimal routing configuration once a failure has occurred.

\section{Conclusion}

\bibliographystyle{IEEEtran}
\nocite{*}
\bibliography{biblio}

\appendix
Short reviews of the cited papers.
\subsection{Verifying forwarding plane connectivity \cite{2013arXiv1308.4465K}}
This article presents a way to detect and locate a single arbitrary node or link failure.
In order to do so, the controller will install multiple sets of static routing rules in the switches.

The first set is used to detect whether there is a failure or not in the network.
The main idea is to create an Euler cycle in the network (if the network does not allow one, the trick is to duplicate all link and build a directed graph, which will force the existence of such a cycle). The controller will then attach itself to a node in the network and send a control message. This message will be then propagated around the cycle and will loop back to the controller if all links and node are operating properly.

The second set of forwarding rules is used to locate the failure in the network. The controller will send a second control message which should loop back to the control after reaching a given node. The controller will keep repeating this operation, allowing it to perform a binary search over the nodes until it locates the link or node that has failed.

\textbf{Limitations:}
\begin{itemize}
	\item \textbf{Scalability} This only works in case of a single link or node failure. (As the same node can be in different places fo the cycle thus breaking it multiple times). This is suitable to networks of arbitrary size. Detecting a failure requires up to 6 times the number of links, and takes up to log(\#number of links) control messages.
	\item \textbf{Time} This does not perform recovery, but detection. The detection itself might be 'slow' wrt. forwarding plane speed depending on the size of the network.
	\item \textbf{Overhead} Extremely small as very few control messages have to be sent when no failures are present.
	\item \textbf{Load} The load is insignificant as the controller has a passive role.
\end{itemize}

\textbf{Issue treated}
\begin{itemize}
	\item Node failure
	\item Link failure
\end{itemize}

\textbf{Topic}
\begin{itemize}
	\item Detection
\end{itemize}

\subsection{FatTire: Declarative Fault Tolerance for SDN \cite{Reitblatt:2013:FDF:2491185.2491187}}
This paper introduces a new language constructs that enable a programmer to specify flow invariant, even in case of failure. This construction is then compiled in order to generate backup forwarding table entries using OpenFlow fast failover mechanism and installed on the switches.
The paper describes the language syntax as well as its implementation.

\textbf{Limitations:}
\begin{itemize}
	\item \textbf{Scalability} This will require switches to have huge forwarding tables if it wants to account for every possible failure (if the programmer enabled FatTire for all possible flows). Scales linearly with the number of interfaces and the number of flow destinations. It can handle arbitrary number of failures
	\item \textbf{Time} Quite fast as the longest part of it is taken by the detection mechanism. The recovery itself is preinstalled in the flow tables.
	\item \textbf{Load} Not constant load on the controller.
\end{itemize}

\textbf{Issue treated}
\begin{itemize}
	\item Node failure
	\item Link failure
\end{itemize}

\textbf{Topic}
\begin{itemize}
	\item Protection
\end{itemize}

\subsection{Automatic failure recovery for SDN \cite{Kuzniar:2013:AFR:2491185.2491218}}
This paper advocates the need to separate the failure recovery mechanism on the controller from the forwarding and policy logic. It presents such a framework which is built for the POX controller, and provides a simple module that will handle failures and recover from them allowing developer to write failure-agnostic code.

This framework works in two phases:
\begin{enumerate}
	\item When there are no failures in the network, it records all events that happen on the controller.
	\item When a failure is detected, it performs the recovery in two phases:
		\begin{description}
			\item \textbf{The replay phase} It creates a clean copy of the original controller, minus the failed nodes, and replay all events it has recorded, which leads to a new coherent controller state accounting for the failure.
			\item \textbf{The reconfiguration phase} It pushes the new network state to the controller and the switches
		\end{description}
\end{enumerate}

\textbf{Limitations:}
\begin{itemize}
	\item \textbf{Scalability} The model used to account for failure is always simpler than the real network, so it has virtually no impact.
	\item \textbf{Time} This is a "slow" process, as the configuration change has to be pushed from the controller to the switches after being signaled to the controller.
	\item \textbf{Load} Only when a failure occurs
\end{itemize}

\textbf{Issue treated}
\begin{itemize}
	\item Node failure
	\item Link failure
\end{itemize}

\textbf{Topic}
\begin{itemize}
	\item Recovery
\end{itemize}

\subsection{Enabling fast failure recovery in OpenFlow Networks \cite{2911632}}
The topic of this article is to present a way of doing fast failure recovery in openflow networks.
The idea is to make sure that upon the acknowledgment of a failure by the controller, there is an efficient way to quickly inform the openflow switches.

To do so, the article presents an algorithm on how to recover from a failure fast enough and on the whole network.
For the method to work, there are several requierments from the controller. These are the following:
\begin{itemize}
	\item The controller must know about the failure
	\item The controller must remember the paths it established
	\item The controller must be able to compute a new path
	\item The controller knows all the current flows in the network
\end{itemize}
The algorithm states that upon a link failure, a new path is computed for every path that goes through this link.
Then, in each switch of the network that has an entry related to the old broken path, the entry is delete and new ones are pushed to establish the new path.

The results in the article are restoration times of about 12ms. In large networks, the goal is to propose restoration times that are below 50ms.

\textbf{Limitations:}
\begin{itemize}
	\item \textbf{Scalability} Does not scale well as the controller needs to remember all established paths.
	\item \textbf{Time} The recovery process is "fast" as only few flow are recomputed, but it still needs to wait for the new flows to be installed.
	\item \textbf{Load} Only when a failure occurs
\end{itemize}

\textbf{Issue treated}
\begin{itemize}
	\item Node failure
	\item Link failure
\end{itemize}

\textbf{Topic}
\begin{itemize}
	\item Restoration
\end{itemize}

\subsection{Scalable Fault Management for OpenFlow \cite{6364688}}
This paper present an alternative solution to LLDP to monitor the network health. To do so, the switches are extended to be able to send and to react to OAM (Operation, Administration, and Maintenance) packets.

The advantage taken from this solution is that the controller does not have to worry about monitoring the network for failures anymore. If it had to do it, to be able to react within a certain limit of time (50ms), it would mean send a high amount of LLDP packets per second, per link and per end-to-end tunnel. This causes serious scalability issues in openflow.

In this solution, if a failure occurs, it is detected without the need of the packet to get back to the sender. When a OAM packet is received on the egress side of a tunnel, the switch updates a state accordingly to the packet. For each tunnel monitored at the switch, there is a timer that is updated for each monitoring packet received. If that timer expires, the switch notifies the controller that the tunnel has failed.

\textbf{Limitations:}
\begin{itemize}
	\item \textbf{Scalability} The switches must be somehow intelligents, the advantage of having simple switches is lost.
	\item \textbf{Time} There is no need for response from the targeted switch, the only time constraint is the time that must elapse before a link is considered broken.
	\item \textbf{Overhead} No more than LLDP.
\end{itemize}

\textbf{Issue treated}
\begin{itemize}
	\item Node failure
	\item Link failure
\end{itemize}

\textbf{Topic}
\begin{itemize}
	\item Detection
\end{itemize}

\subsection{Network Architecture for joint Failure Recovery and Traffic Engineering \cite{Suchara:2011:NAJ:1993744.1993756}}
This paper presents a way to unify load balancing and failure recovery.

It first starts by presenting this unified approach in a protocol agnostic way, then presents some experimental results and finally concludes by providing a few hints on how to deploy it in real networks (i.e. by using MPLS, Openflow, \ldots).

The main idea is that routers should be simple forwarding switches, much like in the SDN paradigm. An external management system precomputes multiple paths for each pair of edge routers which have traffic between them. The routers in the network will then perform load balancing by splitting the traffic over the normal paths and the backup paths. If a path fails, the routers will simply remove the failed path from their FIB, and continue forwarding traffic over the remaining paths.

In this system, failures are detected at a path level, by the ingress/egress routers, which will react to the failures themselves by rebalancing the traffic on the remaining path, ignoring the load informations. As this recovery is perform without this information, the edge routers do not need to broadcast real-time updates about the network state, which means that the reaction of a given router to a failure is deterministic. 

\textbf{Limitations:}
\begin{itemize}
	\item \textbf{Scalability} The switches must be able to remember several paths to each destination. 
	\item \textbf{Time} Only time consuming when the paths must be computed. Takes no time when a link goes down.
\end{itemize}

\textbf{Issue treated}
\begin{itemize}
	\item Node failure
	\item Link failure
\end{itemize}

\textbf{Topic}
\begin{itemize}
	\item Protection
	\item Recovery
\end{itemize}

\subsection{Ensuring connectivity via data plane mechanisms \cite{Liu:2013:ECV:2482626.2482639}}
This article presents a way to speed up connectivity by assigning it to the data plane.

In the case of failures, the control plane is typicaly responsible for the recovery and is slower than the data plane by several orders of magnitude. What is proposed here is to delagate to the data plane the task of ensuring connectivity from point to point, so that, in the event of a failure, the recovery is done at the speed of the data plane.

To do so, they implement a variant of the Gafni-Bertsekas link reversal algorithm to build a directed acyclic graph for each destination, where each destination is a sink (no outgoing edges). That way, any path through that tree leads to the destination.

The control plane still keeps a role, that is to ensure that the paths that are used are optimal (eg: shortest paths). The algorithm used is incremental and aims at leading the networks towards shortest paths.

\textbf{Limitations:}
\begin{itemize}
	\item \textbf{Scalability} The aims of sdn is to provide a splitted way of using the data plane and control plane. Here, the bond between them is much stronger.
\end{itemize}

\textbf{Issue treated}
\begin{itemize}
	\item Node failure
	\item Link failure
\end{itemize}

\textbf{Topic}
\begin{itemize}
	\item Recovery
\end{itemize}

\subsection{OpenFlow: Meeting carrier-grade recovery requirements \cite{Sharma:2013:OMC:2445634.2445903}}
This paper presents a performance evaluation of the standard technique used to handle failures in Openflow networks in order to meet carrier grade requirements: sub 50ms recovery time (thus mainly using path protection technique).

This paper does not present new techniques, but rather focuses on the evaluation of the performance of the fast-failover mechanism in Openflow. 

\textbf{Limitation of the paper:}
Those performance are the result of simulations, in a controller environment. Furthermore, due to how the simulation was ran, they had troubles identifying the exact at which links were brought down to simulate a failure, thus impacting the precision of their measurements.
\end{document}